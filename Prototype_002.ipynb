{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwPrfpx+5vckVSjxWB54Eb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CyberMetrics/Prototypes/blob/prototype02_modified/Prototype_002.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive;drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "VzVJ5jVCdHmI",
        "outputId": "27b17d68-7e63-4a17-d971-604626301b08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "from collections import deque\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from pandas import json_normalize\n",
        "from google.colab import drive\n",
        "from datetime import datetime\n",
        "import os\n",
        "from typing import Dict, Any, List\n",
        "import io # Needed for DataFrame to_markdown fallback (optional)\n",
        "\n",
        "# --- Configuration: Define the Drive Paths ---\n",
        "# WARNING: ENSURE THIS PATH IS CORRECT FOR YOUR DRIVE SETUP!\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/Capstone Mark-01/'\n",
        "TRAIN_FILE_PATH = DRIVE_BASE_PATH + 'wazuh_sample(json).json'\n",
        "LIVE_INPUT_PATH = DRIVE_BASE_PATH + 'live_security_feed.json'"
      ],
      "metadata": {
        "id": "99CTkcqMmWQT"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ====================================================================\n",
        "# 1. CORE ML MODEL (LOGISTIC REGRESSION)\n",
        "# ====================================================================\n",
        "\n",
        "class SimpleLogisticRegression:\n",
        "    def __init__(self, lr=0.01, epochs=1000):\n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.w = None\n",
        "        self.b = 0\n",
        "\n",
        "    def _sigmoid(self, z):\n",
        "        z_clip = np.clip(z, -500, 500)\n",
        "        return 1 / (1 + np.exp(-z_clip))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.array(X, dtype=float)\n",
        "        y = np.array(y, dtype=float)\n",
        "        n, d = X.shape\n",
        "        self.w = np.zeros(d)\n",
        "        self.b = 0\n",
        "\n",
        "        for _ in range(self.epochs):\n",
        "            z = X.dot(self.w) + self.b\n",
        "            pred = self._sigmoid(z)\n",
        "            grad_w = (1/n) * X.T.dot(pred - y)\n",
        "            grad_b = (1/n) * np.sum(pred - y)\n",
        "            self.w -= self.lr * grad_w\n",
        "            self.b -= self.lr * grad_b\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        X = np.array(X, dtype=float)\n",
        "        z = X.dot(self.w) + self.b\n",
        "        return self._sigmoid(z)"
      ],
      "metadata": {
        "id": "KMlxEQfwnqbT"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# 2. WAZUH EVENT ANALYZER (CORE LOGIC)\n",
        "# ====================================================================\n",
        "\n",
        "class WazuhEventAnalyzer:\n",
        "    def __init__(self, lr=0.01, epochs=1000):\n",
        "        self.classifier = SimpleLogisticRegression(lr=lr, epochs=epochs)\n",
        "        self.label_encoders = {}\n",
        "        self.is_trained = False\n",
        "        self.rule_counts = pd.Series()\n",
        "        self.feature_cols = [\n",
        "            'rule_level_scaled',\n",
        "            'rule_id_scaled',\n",
        "            'severity_encoded',\n",
        "            'status_encoded',\n",
        "            'Anomaly_Flag'\n",
        "        ]\n",
        "\n",
        "    def _preprocess(self, df):\n",
        "        df_proc = df.copy()\n",
        "        df_proc['is_critical_event'] = df_proc['severity'].apply(\n",
        "            lambda x: 1 if str(x).lower() in ['high', 'critical'] else 0\n",
        "        )\n",
        "\n",
        "        categorical_cols = ['agent_name', 'status', 'severity', 'action', 'event_type', 'system']\n",
        "        for col in categorical_cols:\n",
        "            if col in df_proc.columns:\n",
        "                le = self.label_encoders.get(col, LabelEncoder())\n",
        "\n",
        "                def safe_transform(x):\n",
        "                    x_str = str(x)\n",
        "                    if col not in self.label_encoders:\n",
        "                        return le.fit_transform([x_str])[0]\n",
        "                    try:\n",
        "                        return le.transform([x_str])[0]\n",
        "                    except ValueError:\n",
        "                        return -1\n",
        "\n",
        "                df_proc[f'{col}_encoded'] = df_proc[col].apply(safe_transform)\n",
        "                if col not in self.label_encoders:\n",
        "                    self.label_encoders[col] = le\n",
        "\n",
        "        numeric_cols_to_scale = ['rule_id', 'rule_level']\n",
        "        for col in numeric_cols_to_scale:\n",
        "            if col in df_proc.columns:\n",
        "                data = df_proc[col].values.reshape(-1, 1)\n",
        "                scaler = self.label_encoders.get(col)\n",
        "\n",
        "                if scaler is None:\n",
        "                    scaler = StandardScaler()\n",
        "                    df_proc[f'{col}_scaled'] = scaler.fit_transform(data)\n",
        "                    self.label_encoders[col] = scaler\n",
        "                else:\n",
        "                    df_proc[f'{col}_scaled'] = scaler.transform(data)\n",
        "\n",
        "        df_proc['timestamp'] = pd.to_datetime(df_proc['timestamp'], errors='coerce')\n",
        "        df_proc = df_proc.sort_values('timestamp').reset_index(drop=True)\n",
        "        time_diff = df_proc['timestamp'].diff().dt.total_seconds().fillna(0)\n",
        "        df_proc['time_delta_inv'] = 1 / (time_diff + 1e-6)\n",
        "\n",
        "        return df_proc\n",
        "\n",
        "    def fit(self, df):\n",
        "        df_proc = self._preprocess(df)\n",
        "        self.rule_counts = df_proc[\"rule_id\"].value_counts()\n",
        "\n",
        "        df_proc['Anomaly_Flag'] = df_proc[\"rule_id\"].apply(\n",
        "            lambda x: 1 if self.rule_counts.get(x, 0) <= 1 else 0\n",
        "        )\n",
        "\n",
        "        X = df_proc[self.feature_cols]\n",
        "        y = df_proc['is_critical_event']\n",
        "        self.classifier.fit(X.values, y.values)\n",
        "        self.is_trained = True\n",
        "        print(f\"Classifier trained with {len(X)} samples. Feature columns: {self.feature_cols}\")\n",
        "\n",
        "    def analyze(self, df):\n",
        "        if df.empty:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df_proc = self._preprocess(df)\n",
        "\n",
        "        def get_anomaly_flag(rule_id):\n",
        "            is_rare_or_new = self.rule_counts.get(rule_id, 0) <= 1\n",
        "            return 1 if is_rare_or_new else 0\n",
        "\n",
        "        df_proc['Anomaly_Flag'] = df_proc[\"rule_id\"].apply(get_anomaly_flag)\n",
        "\n",
        "        if not self.is_trained:\n",
        "            df_proc['ML_Proba'] = 0.5\n",
        "        else:\n",
        "            X_test = df_proc[self.feature_cols]\n",
        "            df_proc['ML_Proba'] = self.classifier.predict_proba(X_test.values)\n",
        "\n",
        "        seq_alert_check = df_proc.groupby('srcip')['time_delta_inv'].transform(\n",
        "             lambda x: x.rolling(window=3, min_periods=1).mean()\n",
        "        )\n",
        "        df_proc['Seq_Alert'] = (df_proc['time_delta_inv'] > seq_alert_check.shift(1).fillna(0) * 2).astype(int)\n",
        "\n",
        "        df_proc['Final_Score'] = (\n",
        "            df_proc['ML_Proba'] * 0.5 +\n",
        "            df_proc['Anomaly_Flag'] * 0.3 +\n",
        "            df_proc['Seq_Alert'] * 0.2\n",
        "        )\n",
        "        df_proc['FinalAlert'] = (df_proc['Final_Score'] > 0.75).astype(int)\n",
        "\n",
        "        return df_proc[['timestamp', 'srcip', 'severity', 'rule_id', 'rule_level',\n",
        "                        'Anomaly_Flag', 'Seq_Alert', 'ML_Proba', 'Final_Score', 'FinalAlert']]\n",
        "\n"
      ],
      "metadata": {
        "id": "pWnECA7HnwOm"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================================\n",
        "# 3. CONTINUOUS DRIVE MONITORING LOGIC\n",
        "# ====================================================================\n",
        "\n",
        "def create_scaler_booster_data(agent_id_prefix):\n",
        "    \"\"\"Creates synthetic data mirroring Agent's high rule ranges for stable scaling.\"\"\"\n",
        "    return pd.DataFrame([\n",
        "        {'timestamp': '2025-01-01T00:00:00Z', 'srcip': '1.1.1.1', 'dstip': '2.2.2.2',\n",
        "         'event_type': 'brute_force_attempt', 'action': 'block', 'status': 'failed',\n",
        "         'severity': 'Critical', 'group': '[api_booster]', 'message': 'Booster data high level',\n",
        "         'system': 'linux', 'rule_id': 900101, 'rule_level': 16,\n",
        "         'agent_id': agent_id_prefix + '99', 'agent_name': 'firewall-gateway'},\n",
        "        {'timestamp': '2025-01-01T00:00:01Z', 'srcip': '1.1.1.1', 'dstip': '2.2.2.2',\n",
        "         'event_type': 'network_connection', 'action': 'allow', 'status': 'success',\n",
        "         'severity': 'Low', 'group': '[api_booster]', 'message': 'Booster data low level',\n",
        "         'system': 'linux', 'rule_id': 900350, 'rule_level': 4,\n",
        "         'agent_id': agent_id_prefix + '99', 'agent_name': 'firewall-gateway'},\n",
        "    ])\n",
        "\n",
        "def load_and_prepare_training_data(file_path):\n",
        "    \"\"\"Loads and flattens training data, injecting custom rules for stable scaling.\"\"\"\n",
        "    df_full = pd.read_json(file_path, lines=True)\n",
        "    df_flat = json_normalize(df_full.to_dict(orient='records'), sep='.')\n",
        "\n",
        "    required_context_cols = ['timestamp', 'srcip', 'dstip', 'event_type', 'action', 'status',\n",
        "                             'severity', 'group', 'message', 'system']\n",
        "\n",
        "    final_df_original = df_flat[required_context_cols].copy()\n",
        "    final_df_original['rule_id'] = df_flat['rule.id']\n",
        "    final_df_original['rule_level'] = df_flat['rule.level']\n",
        "    final_df_original['agent_id'] = df_flat['agent.id']\n",
        "    final_df_original['agent_name'] = df_flat['agent.name']\n",
        "\n",
        "    df_booster = create_scaler_booster_data('00')\n",
        "    df_combined = pd.concat([final_df_original.head(800), df_booster], ignore_index=True)\n",
        "\n",
        "    df_combined['rule_id'] = pd.to_numeric(df_combined['rule_id'], errors='coerce')\n",
        "    df_combined['rule_level'] = pd.to_numeric(df_combined['rule_level'], errors='coerce')\n",
        "\n",
        "    return df_combined\n",
        "\n"
      ],
      "metadata": {
        "id": "7qLiiddHn2U1"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def continuous_live_analysis(analyzer):\n",
        "    \"\"\"Monitors the Drive file for new lines and processes them in batches.\"\"\"\n",
        "\n",
        "    BATCH_SIZE = 5\n",
        "    f = None\n",
        "    new_logs_queue = deque()\n",
        "    total_processed_count = 0\n",
        "\n",
        "    print(\"\\n--- 🧠 Continuous Analyzer Started ---\")\n",
        "    print(f\"Monitoring Live Feed at: {LIVE_INPUT_PATH}\")\n",
        "\n",
        "    # CATCH-UP LOGIC: Reads all existing data on startup (FIXES MISSING BACKLOG DATA)\n",
        "    try:\n",
        "        if os.path.exists(LIVE_INPUT_PATH):\n",
        "            with open(LIVE_INPUT_PATH, 'r', encoding=\"utf-8\") as init_f:\n",
        "                for line in init_f:\n",
        "                    try:\n",
        "                        log_entry = json.loads(line)\n",
        "                        new_logs_queue.append(log_entry)\n",
        "                    except json.JSONDecodeError:\n",
        "                        pass\n",
        "\n",
        "            print(f\"[{datetime.now().strftime('%H:%M:%S')}] ANALYZER: Found {len(new_logs_queue)} backlog events. Starting detailed batch analysis...\")\n",
        "\n",
        "            # Process all backlog events immediately and print detailed results\n",
        "            while len(new_logs_queue) >= BATCH_SIZE:\n",
        "                batch_list = [new_logs_queue.popleft() for _ in range(BATCH_SIZE)]\n",
        "                df_batch = pd.DataFrame(batch_list)\n",
        "\n",
        "                results = analyzer.analyze(df_batch)\n",
        "                total_processed_count += len(df_batch)\n",
        "\n",
        "                # --- BACKLOG REPORTING (SHOWS ALL RESULTS 0/1) ---\n",
        "                display_cols = ['timestamp', 'srcip', 'severity', 'rule_id', 'rule_level',\n",
        "                                'Anomaly_Flag', 'Seq_Alert', 'ML_Proba', 'Final_Score', 'FinalAlert']\n",
        "                display_df = results[display_cols].copy()\n",
        "                critical_count = len(results[results['FinalAlert'] == 1])\n",
        "\n",
        "                print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] --- BACKLOG BATCH (Total: {total_processed_count}) ---\")\n",
        "                if critical_count > 0:\n",
        "                    print(f\"🚨 ALERT COUNT: {critical_count} CRITICAL EVENTS FOUND 🚨\")\n",
        "\n",
        "                try:\n",
        "                    print(display_df.to_markdown(index=False, floatfmt=\".4f\"))\n",
        "                except Exception as markdown_error:\n",
        "                    print(f\"[ERROR DURING FORMATTING: {markdown_error}] Falling back to string output.\")\n",
        "                    print(display_df.to_string(index=False))\n",
        "                print(\"--------------------------------------------------\")\n",
        "\n",
        "            print(f\"[{datetime.now().strftime('%H:%M:%S')}] ANALYZER: Finished initial processing. Total processed: {total_processed_count}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[{datetime.now().strftime('%H:%M:%S')}] ANALYZER: Error during initial catch-up: {e}. Clearing queue.\")\n",
        "        new_logs_queue.clear()\n",
        "\n",
        "    # LIVE MONITORING LOOP (Monitors the end of the file for new Agent writes)\n",
        "    while True:\n",
        "        if f is None:\n",
        "             try:\n",
        "                f = open(LIVE_INPUT_PATH, 'r', encoding=\"utf-8\")\n",
        "                f.seek(0, 1)\n",
        "             except FileNotFoundError:\n",
        "                time.sleep(5)\n",
        "                continue\n",
        "\n",
        "        new_line = f.readline()\n",
        "\n",
        "        if new_line:\n",
        "            try:\n",
        "                log_entry = json.loads(new_line)\n",
        "                new_logs_queue.append(log_entry)\n",
        "\n",
        "                if len(new_logs_queue) >= BATCH_SIZE:\n",
        "                    batch_list = [new_logs_queue.popleft() for _ in range(BATCH_SIZE)]\n",
        "                    df_batch = pd.DataFrame(batch_list)\n",
        "                    results = analyzer.analyze(df_batch)\n",
        "                    total_processed_count += len(df_batch)\n",
        "\n",
        "                    # --- LIVE REPORTING (SHOWS ALL RESULTS 0/1) ---\n",
        "                    display_cols = ['timestamp', 'srcip', 'severity', 'rule_id', 'rule_level',\n",
        "                                    'Anomaly_Flag', 'Seq_Alert', 'ML_Proba', 'Final_Score', 'FinalAlert']\n",
        "                    display_df = results[display_cols].copy()\n",
        "                    critical_count = len(results[results['FinalAlert'] == 1])\n",
        "\n",
        "                    print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] --- LIVE BATCH ANALYSIS (Total: {total_processed_count}) ---\")\n",
        "                    if critical_count > 0:\n",
        "                        print(f\"🚨 ALERT COUNT: {critical_count} CRITICAL EVENTS FOUND 🚨\")\n",
        "\n",
        "                    try:\n",
        "                        print(display_df.to_markdown(index=False, floatfmt=\".4f\"))\n",
        "                    except Exception as markdown_error:\n",
        "                        print(f\"[ERROR DURING FORMATTING: {markdown_error}] Falling back to string output.\")\n",
        "                        print(display_df.to_string(index=False))\n",
        "\n",
        "                    print(\"--------------------------------------------------\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"[{datetime.now().strftime('%H:%M:%S')}] ANALYZER: Runtime Error: {e}. Skipping batch.\")\n",
        "                new_logs_queue.clear()\n",
        "\n",
        "        else:\n",
        "            time.sleep(1)\n",
        "\n"
      ],
      "metadata": {
        "id": "YHpD0lmLn7M7"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Main Analyzer Execution Block ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # 1. Mount Drive (Essential for file access)\n",
        "    try:\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Drive Mounting Warning: {e}\")\n",
        "\n",
        "    # 2. Train the Analyzer (using stability-enhanced data)\n",
        "    try:\n",
        "        print(f\"\\nAttempting to load and train model using: {TRAIN_FILE_PATH}\")\n",
        "\n",
        "        # Load data including the custom rule range booster\n",
        "        df_train = load_and_prepare_training_data(TRAIN_FILE_PATH)\n",
        "\n",
        "        event_analyzer = WazuhEventAnalyzer(lr=0.05, epochs=2000)\n",
        "        event_analyzer.fit(df_train)\n",
        "\n",
        "        print(\"\\n==================================================\")\n",
        "        print(\"SERVER: WazuhEventAnalyzer **RETRAINED** with custom rule ranges.\")\n",
        "        print(\"==================================================\")\n",
        "\n",
        "        # 3. Start the continuous monitoring loop\n",
        "        continuous_live_analysis(event_analyzer)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nANALYZER STOPPED by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\nCRITICAL ANALYZER STARTUP ERROR: {e}\")\n",
        "        print(f\"Please check path: '{TRAIN_FILE_PATH}'.\")"
      ],
      "metadata": {
        "id": "hSrmPZgNoC27",
        "outputId": "9118af56-8a16-461e-801a-19789766625a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "Attempting to load and train model using: /content/drive/MyDrive/Capstone Mark-01/wazuh_sample(json).json\n",
            "Classifier trained with 802 samples. Feature columns: ['rule_level_scaled', 'rule_id_scaled', 'severity_encoded', 'status_encoded', 'Anomaly_Flag']\n",
            "\n",
            "==================================================\n",
            "SERVER: WazuhEventAnalyzer **RETRAINED** with custom rule ranges.\n",
            "==================================================\n",
            "\n",
            "--- 🧠 Continuous Analyzer Started ---\n",
            "Monitoring Live Feed at: /content/drive/MyDrive/Capstone Mark-01/live_security_feed.json\n",
            "[19:49:48] ANALYZER: Found 37 backlog events. Starting detailed batch analysis...\n",
            "\n",
            "[19:49:48] --- BACKLOG BATCH (Total: 5) ---\n",
            "| timestamp                        | srcip        | severity   |   rule_id |   rule_level |   Anomaly_Flag |   Seq_Alert |   ML_Proba |   Final_Score |   FinalAlert |\n",
            "|:---------------------------------|:-------------|:-----------|----------:|-------------:|---------------:|------------:|-----------:|--------------:|-------------:|\n",
            "| 2025-10-30 19:48:49.815000+00:00 | 172.16.1.10  | high       |    900325 |           12 |              1 |           1 |     0.4909 |        0.7454 |            0 |\n",
            "| 2025-10-30 19:48:50.313000+00:00 | 192.168.1.60 | medium     |    900305 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "| 2025-10-30 19:48:50.582000+00:00 | 192.168.1.54 | medium     |    900396 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "| 2025-10-30 19:48:50.756000+00:00 | 192.168.1.57 | medium     |    900368 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "| 2025-10-30 19:48:51.126000+00:00 | 192.168.1.35 | low        |    900302 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "--------------------------------------------------\n",
            "\n",
            "[19:49:48] --- BACKLOG BATCH (Total: 10) ---\n",
            "🚨 ALERT COUNT: 2 CRITICAL EVENTS FOUND 🚨\n",
            "| timestamp                        | srcip        | severity   |   rule_id |   rule_level |   Anomaly_Flag |   Seq_Alert |   ML_Proba |   Final_Score |   FinalAlert |\n",
            "|:---------------------------------|:-------------|:-----------|----------:|-------------:|---------------:|------------:|-----------:|--------------:|-------------:|\n",
            "| 2025-10-30 19:48:51.381000+00:00 | 192.168.1.68 | medium     |    900363 |            5 |              1 |           1 |     0.5226 |        0.7613 |            1 |\n",
            "| 2025-10-30 19:48:51.526000+00:00 | 172.16.1.10  | high       |    900377 |           12 |              1 |           0 |     0.4909 |        0.5454 |            0 |\n",
            "| 2025-10-30 19:48:51.999000+00:00 | 192.168.1.27 | low        |    900332 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "| 2025-10-30 19:48:52.156000+00:00 | 192.168.1.33 | low        |    900392 |            4 |              1 |           1 |     0.5272 |        0.7636 |            1 |\n",
            "| 2025-10-30 19:48:52.369000+00:00 | 192.168.1.21 | low        |    900340 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "--------------------------------------------------\n",
            "\n",
            "[19:49:48] --- BACKLOG BATCH (Total: 15) ---\n",
            "🚨 ALERT COUNT: 1 CRITICAL EVENTS FOUND 🚨\n",
            "| timestamp                        | srcip        | severity   |   rule_id |   rule_level |   Anomaly_Flag |   Seq_Alert |   ML_Proba |   Final_Score |   FinalAlert |\n",
            "|:---------------------------------|:-------------|:-----------|----------:|-------------:|---------------:|------------:|-----------:|--------------:|-------------:|\n",
            "| 2025-10-30 19:48:52.523000+00:00 | 192.168.1.81 | medium     |    900330 |            5 |              1 |           1 |     0.5226 |        0.7613 |            1 |\n",
            "| 2025-10-30 19:48:52.825000+00:00 | 203.0.113.5  | critical   |    900101 |           15 |              1 |           0 |     0.4773 |        0.5386 |            0 |\n",
            "| 2025-10-30 19:48:53.283000+00:00 | 203.0.113.5  | critical   |    900101 |           15 |              1 |           0 |     0.4773 |        0.5386 |            0 |\n",
            "| 2025-10-30 19:48:53.609000+00:00 | 203.0.113.5  | critical   |    900101 |           15 |              1 |           0 |     0.4773 |        0.5386 |            0 |\n",
            "| 2025-10-30 19:48:53.973000+00:00 | 203.0.113.5  | critical   |    900101 |           15 |              1 |           0 |     0.4773 |        0.5386 |            0 |\n",
            "--------------------------------------------------\n",
            "\n",
            "[19:49:48] --- BACKLOG BATCH (Total: 20) ---\n",
            "🚨 ALERT COUNT: 2 CRITICAL EVENTS FOUND 🚨\n",
            "| timestamp                        | srcip        | severity   |   rule_id |   rule_level |   Anomaly_Flag |   Seq_Alert |   ML_Proba |   Final_Score |   FinalAlert |\n",
            "|:---------------------------------|:-------------|:-----------|----------:|-------------:|---------------:|------------:|-----------:|--------------:|-------------:|\n",
            "| 2025-10-30 19:48:54.448000+00:00 | 192.168.1.21 | low        |    900373 |            4 |              1 |           1 |     0.5272 |        0.7636 |            1 |\n",
            "| 2025-10-30 19:48:54.638000+00:00 | 192.168.1.38 | low        |    900367 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "| 2025-10-30 19:48:55.005000+00:00 | 192.168.1.45 | low        |    900300 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "| 2025-10-30 19:48:55.162000+00:00 | 192.168.1.15 | low        |    900399 |            4 |              1 |           1 |     0.5272 |        0.7636 |            1 |\n",
            "| 2025-10-30 19:48:55.440000+00:00 | 192.168.1.74 | medium     |    900369 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "--------------------------------------------------\n",
            "\n",
            "[19:49:48] --- BACKLOG BATCH (Total: 25) ---\n",
            "🚨 ALERT COUNT: 1 CRITICAL EVENTS FOUND 🚨\n",
            "| timestamp                        | srcip        | severity   |   rule_id |   rule_level |   Anomaly_Flag |   Seq_Alert |   ML_Proba |   Final_Score |   FinalAlert |\n",
            "|:---------------------------------|:-------------|:-----------|----------:|-------------:|---------------:|------------:|-----------:|--------------:|-------------:|\n",
            "| 2025-10-30 19:48:55.918000+00:00 | 203.0.113.5  | critical   |    900101 |           15 |              1 |           1 |     0.4773 |        0.7386 |            0 |\n",
            "| 2025-10-30 19:48:56.361000+00:00 | 192.168.1.40 | low        |    900324 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "| 2025-10-30 19:48:56.479000+00:00 | 192.168.1.20 | low        |    900381 |            4 |              1 |           1 |     0.5272 |        0.7636 |            1 |\n",
            "| 2025-10-30 19:48:56.910000+00:00 | 192.168.1.77 | medium     |    900386 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "| 2025-10-30 19:48:57.202000+00:00 | 192.168.1.21 | low        |    900349 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "--------------------------------------------------\n",
            "\n",
            "[19:49:48] --- BACKLOG BATCH (Total: 30) ---\n",
            "🚨 ALERT COUNT: 1 CRITICAL EVENTS FOUND 🚨\n",
            "| timestamp                        | srcip        | severity   |   rule_id |   rule_level |   Anomaly_Flag |   Seq_Alert |   ML_Proba |   Final_Score |   FinalAlert |\n",
            "|:---------------------------------|:-------------|:-----------|----------:|-------------:|---------------:|------------:|-----------:|--------------:|-------------:|\n",
            "| 2025-10-30 19:48:57.683000+00:00 | 192.168.1.84 | medium     |    900303 |            5 |              1 |           1 |     0.5226 |        0.7613 |            1 |\n",
            "| 2025-10-30 19:48:57.854000+00:00 | 192.168.1.63 | medium     |    900330 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "| 2025-10-30 19:48:58.165000+00:00 | 203.0.113.5  | critical   |    900101 |           15 |              1 |           0 |     0.4773 |        0.5386 |            0 |\n",
            "| 2025-10-30 19:48:58.413000+00:00 | 192.168.1.57 | medium     |    900309 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "| 2025-10-30 19:48:58.774000+00:00 | 203.0.113.5  | critical   |    900101 |           15 |              1 |           0 |     0.4773 |        0.5386 |            0 |\n",
            "--------------------------------------------------\n",
            "\n",
            "[19:49:49] --- BACKLOG BATCH (Total: 35) ---\n",
            "🚨 ALERT COUNT: 1 CRITICAL EVENTS FOUND 🚨\n",
            "| timestamp                        | srcip        | severity   |   rule_id |   rule_level |   Anomaly_Flag |   Seq_Alert |   ML_Proba |   Final_Score |   FinalAlert |\n",
            "|:---------------------------------|:-------------|:-----------|----------:|-------------:|---------------:|------------:|-----------:|--------------:|-------------:|\n",
            "| 2025-10-30 19:48:59.066000+00:00 | 192.168.1.43 | low        |    900305 |            4 |              1 |           1 |     0.5272 |        0.7636 |            1 |\n",
            "| 2025-10-30 19:48:59.284000+00:00 | 172.16.1.10  | high       |    900385 |           12 |              1 |           0 |     0.4909 |        0.5454 |            0 |\n",
            "| 2025-10-30 19:48:59.581000+00:00 | 192.168.1.71 | medium     |    900359 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "| 2025-10-30 19:48:59.876000+00:00 | 172.16.1.10  | high       |    900390 |           12 |              1 |           0 |     0.4909 |        0.5454 |            0 |\n",
            "| 2025-10-30 19:49:00.136000+00:00 | 192.168.1.33 | low        |    900360 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "--------------------------------------------------\n",
            "[19:49:49] ANALYZER: Finished initial processing. Total processed: 35\n",
            "\n",
            "[19:49:49] --- LIVE BATCH ANALYSIS (Total: 40) ---\n",
            "🚨 ALERT COUNT: 1 CRITICAL EVENTS FOUND 🚨\n",
            "| timestamp                        | srcip        | severity   |   rule_id |   rule_level |   Anomaly_Flag |   Seq_Alert |   ML_Proba |   Final_Score |   FinalAlert |\n",
            "|:---------------------------------|:-------------|:-----------|----------:|-------------:|---------------:|------------:|-----------:|--------------:|-------------:|\n",
            "| 2025-10-30 19:48:49.815000+00:00 | 172.16.1.10  | high       |    900325 |           12 |              1 |           1 |     0.4909 |        0.7454 |            0 |\n",
            "| 2025-10-30 19:48:50.313000+00:00 | 192.168.1.60 | medium     |    900305 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "| 2025-10-30 19:48:50.582000+00:00 | 192.168.1.54 | medium     |    900396 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "| 2025-10-30 19:49:00.582000+00:00 | 192.168.1.91 | medium     |    900313 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "| 2025-10-30 19:49:01.047000+00:00 | 192.168.1.97 | medium     |    900311 |            5 |              1 |           1 |     0.5226 |        0.7613 |            1 |\n",
            "--------------------------------------------------\n",
            "\n",
            "[19:49:49] --- LIVE BATCH ANALYSIS (Total: 45) ---\n",
            "🚨 ALERT COUNT: 1 CRITICAL EVENTS FOUND 🚨\n",
            "| timestamp                        | srcip        | severity   |   rule_id |   rule_level |   Anomaly_Flag |   Seq_Alert |   ML_Proba |   Final_Score |   FinalAlert |\n",
            "|:---------------------------------|:-------------|:-----------|----------:|-------------:|---------------:|------------:|-----------:|--------------:|-------------:|\n",
            "| 2025-10-30 19:48:50.756000+00:00 | 192.168.1.57 | medium     |    900368 |            5 |              1 |           1 |     0.5226 |        0.7613 |            1 |\n",
            "| 2025-10-30 19:48:51.126000+00:00 | 192.168.1.35 | low        |    900302 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "| 2025-10-30 19:48:51.381000+00:00 | 192.168.1.68 | medium     |    900363 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "| 2025-10-30 19:48:51.526000+00:00 | 172.16.1.10  | high       |    900377 |           12 |              1 |           0 |     0.4909 |        0.5454 |            0 |\n",
            "| 2025-10-30 19:48:51.999000+00:00 | 192.168.1.27 | low        |    900332 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "--------------------------------------------------\n",
            "\n",
            "[19:49:49] --- LIVE BATCH ANALYSIS (Total: 50) ---\n",
            "🚨 ALERT COUNT: 1 CRITICAL EVENTS FOUND 🚨\n",
            "| timestamp                        | srcip        | severity   |   rule_id |   rule_level |   Anomaly_Flag |   Seq_Alert |   ML_Proba |   Final_Score |   FinalAlert |\n",
            "|:---------------------------------|:-------------|:-----------|----------:|-------------:|---------------:|------------:|-----------:|--------------:|-------------:|\n",
            "| 2025-10-30 19:48:52.156000+00:00 | 192.168.1.33 | low        |    900392 |            4 |              1 |           1 |     0.5272 |        0.7636 |            1 |\n",
            "| 2025-10-30 19:48:52.369000+00:00 | 192.168.1.21 | low        |    900340 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "| 2025-10-30 19:48:52.523000+00:00 | 192.168.1.81 | medium     |    900330 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "| 2025-10-30 19:48:52.825000+00:00 | 203.0.113.5  | critical   |    900101 |           15 |              1 |           0 |     0.4773 |        0.5386 |            0 |\n",
            "| 2025-10-30 19:48:53.283000+00:00 | 203.0.113.5  | critical   |    900101 |           15 |              1 |           0 |     0.4773 |        0.5386 |            0 |\n",
            "--------------------------------------------------\n",
            "\n",
            "[19:49:49] --- LIVE BATCH ANALYSIS (Total: 55) ---\n",
            "🚨 ALERT COUNT: 1 CRITICAL EVENTS FOUND 🚨\n",
            "| timestamp                        | srcip        | severity   |   rule_id |   rule_level |   Anomaly_Flag |   Seq_Alert |   ML_Proba |   Final_Score |   FinalAlert |\n",
            "|:---------------------------------|:-------------|:-----------|----------:|-------------:|---------------:|------------:|-----------:|--------------:|-------------:|\n",
            "| 2025-10-30 19:48:53.609000+00:00 | 203.0.113.5  | critical   |    900101 |           15 |              1 |           1 |     0.4773 |        0.7386 |            0 |\n",
            "| 2025-10-30 19:48:53.973000+00:00 | 203.0.113.5  | critical   |    900101 |           15 |              1 |           0 |     0.4773 |        0.5386 |            0 |\n",
            "| 2025-10-30 19:48:54.448000+00:00 | 192.168.1.21 | low        |    900373 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "| 2025-10-30 19:48:54.638000+00:00 | 192.168.1.38 | low        |    900367 |            4 |              1 |           1 |     0.5272 |        0.7636 |            1 |\n",
            "| 2025-10-30 19:48:55.005000+00:00 | 192.168.1.45 | low        |    900300 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "--------------------------------------------------\n",
            "\n",
            "[19:49:49] --- LIVE BATCH ANALYSIS (Total: 60) ---\n",
            "🚨 ALERT COUNT: 2 CRITICAL EVENTS FOUND 🚨\n",
            "| timestamp                        | srcip        | severity   |   rule_id |   rule_level |   Anomaly_Flag |   Seq_Alert |   ML_Proba |   Final_Score |   FinalAlert |\n",
            "|:---------------------------------|:-------------|:-----------|----------:|-------------:|---------------:|------------:|-----------:|--------------:|-------------:|\n",
            "| 2025-10-30 19:48:55.162000+00:00 | 192.168.1.15 | low        |    900399 |            4 |              1 |           1 |     0.5272 |        0.7636 |            1 |\n",
            "| 2025-10-30 19:48:55.440000+00:00 | 192.168.1.74 | medium     |    900369 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "| 2025-10-30 19:48:55.918000+00:00 | 203.0.113.5  | critical   |    900101 |           15 |              1 |           0 |     0.4773 |        0.5386 |            0 |\n",
            "| 2025-10-30 19:48:56.361000+00:00 | 192.168.1.40 | low        |    900324 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "| 2025-10-30 19:48:56.479000+00:00 | 192.168.1.20 | low        |    900381 |            4 |              1 |           1 |     0.5272 |        0.7636 |            1 |\n",
            "--------------------------------------------------\n",
            "\n",
            "[19:49:49] --- LIVE BATCH ANALYSIS (Total: 65) ---\n",
            "🚨 ALERT COUNT: 2 CRITICAL EVENTS FOUND 🚨\n",
            "| timestamp                        | srcip        | severity   |   rule_id |   rule_level |   Anomaly_Flag |   Seq_Alert |   ML_Proba |   Final_Score |   FinalAlert |\n",
            "|:---------------------------------|:-------------|:-----------|----------:|-------------:|---------------:|------------:|-----------:|--------------:|-------------:|\n",
            "| 2025-10-30 19:48:56.910000+00:00 | 192.168.1.77 | medium     |    900386 |            5 |              1 |           1 |     0.5226 |        0.7613 |            1 |\n",
            "| 2025-10-30 19:48:57.202000+00:00 | 192.168.1.21 | low        |    900349 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "| 2025-10-30 19:48:57.683000+00:00 | 192.168.1.84 | medium     |    900303 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "| 2025-10-30 19:48:57.854000+00:00 | 192.168.1.63 | medium     |    900330 |            5 |              1 |           1 |     0.5226 |        0.7613 |            1 |\n",
            "| 2025-10-30 19:48:58.165000+00:00 | 203.0.113.5  | critical   |    900101 |           15 |              1 |           0 |     0.4773 |        0.5386 |            0 |\n",
            "--------------------------------------------------\n",
            "\n",
            "[19:49:49] --- LIVE BATCH ANALYSIS (Total: 70) ---\n",
            "🚨 ALERT COUNT: 1 CRITICAL EVENTS FOUND 🚨\n",
            "| timestamp                        | srcip        | severity   |   rule_id |   rule_level |   Anomaly_Flag |   Seq_Alert |   ML_Proba |   Final_Score |   FinalAlert |\n",
            "|:---------------------------------|:-------------|:-----------|----------:|-------------:|---------------:|------------:|-----------:|--------------:|-------------:|\n",
            "| 2025-10-30 19:48:58.413000+00:00 | 192.168.1.57 | medium     |    900309 |            5 |              1 |           1 |     0.5226 |        0.7613 |            1 |\n",
            "| 2025-10-30 19:48:58.774000+00:00 | 203.0.113.5  | critical   |    900101 |           15 |              1 |           0 |     0.4773 |        0.5386 |            0 |\n",
            "| 2025-10-30 19:48:59.066000+00:00 | 192.168.1.43 | low        |    900305 |            4 |              1 |           0 |     0.5272 |        0.5636 |            0 |\n",
            "| 2025-10-30 19:48:59.284000+00:00 | 172.16.1.10  | high       |    900385 |           12 |              1 |           0 |     0.4909 |        0.5454 |            0 |\n",
            "| 2025-10-30 19:48:59.581000+00:00 | 192.168.1.71 | medium     |    900359 |            5 |              1 |           0 |     0.5226 |        0.5613 |            0 |\n",
            "--------------------------------------------------\n",
            "\n",
            "ANALYZER STOPPED by user.\n"
          ]
        }
      ]
    }
  ]
}